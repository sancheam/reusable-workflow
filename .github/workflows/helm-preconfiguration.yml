name: Helm Preconfiguration

on:
  workflow_call:
    secrets:
      ACCOUNT_ID_NONPROD:
        required: true
      AWS_ACCESS_KEY_ID_NONPROD:
        required: true
      AWS_SECRET_ACCESS_KEY_NONPROD:
        required: true
      ACCOUNT_ID_PROD:
        required: true
      AWS_ACCESS_KEY_ID_PROD:
        required: true
      AWS_SECRET_ACCESS_KEY_PROD:
        required: true
      AWS_REGION:
        required: true
    inputs:
      aws_environment:
        required: true
        type: string
      eks_name:
        required: true
        type: string

jobs:
  helm_preconfiguration:
    runs-on: [os-small-amd64-linux]
    env: 
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCESS_KEY_ID: AWS_ACCESS_KEY_ID_${{ inputs.aws_environment }}
      AWS_SECRET_ACCESS_KEY: AWS_SECRET_ACCESS_KEY_${{ inputs.aws_environment }}
      AWS_ACCOUNT_ID: ACCOUNT_ID_${{ inputs.aws_environment }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Configure AWS Credentials 
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets[env.AWS_ACCESS_KEY_ID] }}
          aws-secret-access-key: ${{ secrets[env.AWS_SECRET_ACCESS_KEY] }}
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: arn:aws:iam::${{ secrets[env.AWS_ACCOUNT_ID] }}:role/TeamAdmin
          role-skip-session-tagging: true

      - name: Get Caller Identity
        run: |
          aws sts get-caller-identity

      - name: Configure Kube Config
        run: |
          aws eks --region ${{ env.AWS_REGION }} update-kubeconfig --name ${{ inputs.eks_name }}

      - name: SSM Session Manager
        run: |
          CLUSTER_API=$(aws eks describe-cluster --region ${{ env.AWS_REGION }} --name ${{ inputs.eks_name }} | jq -r '.cluster.endpoint' | awk -F/ '{print $3}')
          sed -ie "s/https:\/\/$CLUSTER_API/https:\/\/$CLUSTER_API:8443/" ~/.kube/config
          sudo -- sh -c "echo 127.0.0.1 $CLUSTER_API >> /etc/hosts"

          INSTANCE_ID=`aws ec2 describe-instances --filters Name=tag:Name,Values=BastionHost Name=instance-state-name,Values=running --query "Reservations[*].Instances[*].InstanceId" --region ${{ env.AWS_REGION }} --output text`
          nohup aws ssm start-session \
          --target $INSTANCE_ID \
          --document-name AWS-StartPortForwardingSessionToRemoteHost \
          --parameters '{"host":["'"$CLUSTER_API"'"],"portNumber":["443"], "localPortNumber":["8443"]}' \
          --region ${{ env.AWS_REGION }} > nohup.out &
          for attempt in {1..20}; do sleep 1; if grep "Waiting for connections..." nohup.out; then echo ready; break; fi; echo waiting...; done
